{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e51465",
   "metadata": {},
   "source": [
    "### Cell 1: Ekstrak Solusi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2918bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Ekstraksi solusi: 47 kasus di-mapping.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "PROCESSED_DIR = os.path.join(\"..\", \"data\", \"processed\")\n",
    "CSV_PATH      = os.path.join(PROCESSED_DIR, \"cases_cleaned.csv\")\n",
    "\n",
    "# Load data kasus\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Ekstrak solusi: gunakan ringkasan_fakta sebagai solution_text\n",
    "df['solution_text'] = df['ringkasan_fakta']\n",
    "\n",
    "# Peta case_id â†’ solution_text\n",
    "case_solutions = dict(zip(df['case_id'], df['solution_text']))\n",
    "\n",
    "print(f\"[i] Ekstraksi solusi: {len(case_solutions)} kasus di-mapping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60036bf",
   "metadata": {},
   "source": [
    "### Cell 2: Algoritma Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "136fb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Majority vote: pilih case_id paling sering muncul\n",
    "def predict_outcome_majority(topk_ids):\n",
    "    cnt = Counter(topk_ids)\n",
    "    return cnt.most_common(1)[0][0]\n",
    "\n",
    "# Weighted similarity: bobot=skor\n",
    "def predict_outcome_weighted(topk_ids, topk_scores):\n",
    "    cnt = Counter()\n",
    "    for cid, sc in zip(topk_ids, topk_scores):\n",
    "        cnt[cid] += sc\n",
    "    return cnt.most_common(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579a8bf",
   "metadata": {},
   "source": [
    "### Cell 3: Implementasi Fungsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc2ce47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority: 1 (satu) buku pencatatan bulanan warna hijau piutang ppn 2017 (bukti po dari pt. srikandi jawara dunia atas pemesanan 10 (sepuluh) unit genset)\n",
      "Weighted: 1 (satu) buku pencatatan bulanan warna hijau piutang ppn 2017 (bukti po dari pt. srikandi jawara dunia atas pemesanan 10 (sepuluh) unit genset)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import faiss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Paths\n",
    "VEC_DIR     = os.path.join(\"..\", \"data\", \"vectors\")\n",
    "VEC_PATH    = os.path.join(VEC_DIR, \"tfidf_fulltext_vec.pkl\")\n",
    "\n",
    "# Muat TF-IDF vectorizer\n",
    "with open(VEC_PATH, 'rb') as f:\n",
    "    vec = pickle.load(f)\n",
    "\n",
    "# Siapkan matrix X untuk index\n",
    "texts = df['text_full'].fillna(\"\").tolist()\n",
    "X = vec.transform(texts).toarray().astype('float32')\n",
    "\n",
    "# Build & normalisasi Faiss index\n",
    "index = faiss.IndexFlatIP(X.shape[1])\n",
    "faiss.normalize_L2(X)\n",
    "index.add(X)\n",
    "\n",
    "# Fungsi retrieve berbasis Faiss\n",
    "def retrieve_faiss(query: str, k: int = 5):\n",
    "    qv = vec.transform([query]).toarray().astype('float32')\n",
    "    faiss.normalize_L2(qv)\n",
    "    D, I = index.search(qv, k)\n",
    "    res = df.iloc[I[0]].copy().reset_index(drop=True)\n",
    "    res['score'] = D[0]\n",
    "    return res\n",
    "\n",
    "# Fungsi predict_outcome\n",
    "def predict_outcome(query: str, k: int = 5, method: str = 'majority') -> str:\n",
    "    res = retrieve_faiss(query, k)\n",
    "    ids    = res['case_id'].tolist()\n",
    "    scores = res['score'].tolist()\n",
    "    if method == 'weighted':\n",
    "        cid = predict_outcome_weighted(ids, scores)\n",
    "    else:\n",
    "        cid = predict_outcome_majority(ids)\n",
    "    return case_solutions.get(cid, \"\")\n",
    "\n",
    "# Contoh\n",
    "q = \"penipuan buku pencatatan genset\"\n",
    "print(\"Majority:\", predict_outcome(q, method='majority'))\n",
    "print(\"Weighted:\", predict_outcome(q, method='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3cdb97",
   "metadata": {},
   "source": [
    "### Cell 4: Demo Manual (iv): Demo Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24768ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query       : putusan pn surabaya\n",
      "6/pid\n",
      "Ground-truth: 3 (tiga) lembar nota penjualan, 6 (enam) lembar sales order (so), 5 (lima) lembar copy surat jalan serta 1 (satu) lembar faktur penjualan pt damai sejahtera abadi (ufo elektronik) jl. kertajaya no. 149 surabaya, 5 (lima) tv led merk lg type 32lm550bpta,1 (satu) lembar surat jalan nomor : sjgbhq21110/ 00178, invoice : invktj2110/00469\n",
      "Majority    : putusan pn surabaya\n",
      "679/pid\n",
      "Weighted    : putusan pn surabaya\n",
      "679/pid\n",
      "\n",
      "Query       : putusan pn surabaya\n",
      "1470/pid\n",
      "Ground-truth: 1 (satu) unit sepeda motor yamaha n-max 2dp tahun 2015 warna merah nopol. l-4460-zz noka. mh3sg3120fk023974 nosin. g3e4e0054520 stnk an. agus mulyadi alamat, griya benowo indah ii blok q-10 surabaya\n",
      "Majority    : 1 (satu) unit sepeda motor yamaha n-max 2dp tahun 2015 warna merah nopol. l-4460-zz noka. mh3sg3120fk023974 nosin. g3e4e0054520 stnk an. agus mulyadi alamat, griya benowo indah ii blok q-10 surabaya\n",
      "Weighted    : 1 (satu) unit sepeda motor yamaha n-max 2dp tahun 2015 warna merah nopol. l-4460-zz noka. mh3sg3120fk023974 nosin. g3e4e0054520 stnk an. agus mulyadi alamat, griya benowo indah ii blok q-10 surabaya\n",
      "\n",
      "Query       : putusan pn surabaya\n",
      "1891/pid\n",
      "Ground-truth: putusan pn surabaya\n",
      "1891/pid\n",
      "Majority    : putusan pn surabaya\n",
      "1891/pid\n",
      "Weighted    : putusan pn surabaya\n",
      "1891/pid\n",
      "\n",
      "Query       : putusan pn surabaya\n",
      "2582/pid\n",
      "Ground-truth: 1 (satu) buah bpkb sepeda motor honda beat warna putih biru nopol l 3647 rt tahun 2016\n",
      "Majority    : 1 (satu) buah bpkb sepeda motor honda beat warna putih biru nopol l 3647 rt tahun 2016\n",
      "Weighted    : 1 (satu) buah bpkb sepeda motor honda beat warna putih biru nopol l 3647 rt tahun 2016\n",
      "\n",
      "Query       : putusan pn surabaya\n",
      "877/pid\n",
      "Ground-truth: putusan pn surabaya\n",
      "877/pid\n",
      "Majority    : putusan pn surabaya\n",
      "877/pid\n",
      "Weighted    : putusan pn surabaya\n",
      "877/pid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ambil 5 sampel untuk demo\n",
    "for _, row in df.sample(5, random_state=0).iterrows():\n",
    "    query = row['text_full'].split('.')[0][:100]\n",
    "    true_sol = case_solutions[row['case_id']]\n",
    "    maj = predict_outcome(query, method='majority')\n",
    "    wtd = predict_outcome(query, method='weighted')\n",
    "    print(f\"Query       : {query}\")\n",
    "    print(f\"Ground-truth: {true_sol}\")\n",
    "    print(f\"Majority    : {maj}\")\n",
    "    print(f\"Weighted    : {wtd}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c252418a",
   "metadata": {},
   "source": [
    "### Cell 5: Simpan Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d64eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved: ..\\data\\results\\predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os, json, pickle, faiss\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Paths\n",
    "EVAL_DIR       = os.path.join(\"..\",\"data\",\"eval\")\n",
    "RESULTS_DIR    = os.path.join(\"..\",\"data\",\"results\")\n",
    "VEC_DIR        = os.path.join(\"..\",\"data\",\"vectors\")\n",
    "QUERIES_PATH   = os.path.join(EVAL_DIR, \"queries.json\")\n",
    "VECTOR_PATH    = os.path.join(VEC_DIR, \"tfidf_fulltext_vec.pkl\")\n",
    "PRED_CSV       = os.path.join(RESULTS_DIR, \"predictions.csv\")\n",
    "\n",
    "# Load queries\n",
    "with open(QUERIES_PATH, 'r', encoding='utf-8') as f:\n",
    "    queries = json.load(f)\n",
    "\n",
    "# Load TF-IDF & build Faiss\n",
    "vec = pickle.load(open(VECTOR_PATH, 'rb'))\n",
    "df = pd.read_csv(os.path.join(\"..\",\"data\",\"processed\",\"cases_cleaned.csv\"))\n",
    "X = vec.transform(df[\"text_full\"].fillna(\"\")).toarray().astype(\"float32\")\n",
    "index = faiss.IndexFlatIP(X.shape[1]); faiss.normalize_L2(X); index.add(X)\n",
    "\n",
    "def retrieve_faiss(q, k=5):\n",
    "    v = vec.transform([q]).toarray().astype(\"float32\")\n",
    "    faiss.normalize_L2(v)\n",
    "    D, I = index.search(v, k)\n",
    "    return df.iloc[I[0]][\"case_id\"].tolist()\n",
    "\n",
    "# Generate predictions\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "preds = []\n",
    "for qid, q in enumerate(queries, start=1):\n",
    "    query = q[\"query\"]\n",
    "    gt    = q[\"ground_truth\"]\n",
    "    top5  = retrieve_faiss(query, k=5)\n",
    "    preds.append({\n",
    "        \"query_id\":       qid,\n",
    "        \"ground_truth\":   gt,\n",
    "        \"predicted_case\": top5[0],      # apa adanya\n",
    "        \"top_5_case_ids\": top5\n",
    "    })\n",
    "\n",
    "pd.DataFrame(preds).to_csv(PRED_CSV, index=False, encoding=\"utf-8\")\n",
    "print(\"Predictions saved:\", PRED_CSV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
